{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# код для поиска w_map\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "class Posterior(nn.Module):\n",
    "    def __init__(self, A, vec_size = 10):\n",
    "        super().__init__()\n",
    "        self.vec_size = vec_size\n",
    "\n",
    "        w_init = np.random.multivariate_normal(mean = np.zeros((vec_size)), cov= A)\n",
    "        self.w = torch.tensor(w_init, requires_grad=True, dtype=torch.float32)\n",
    "        # self.w.requires_grad = True\n",
    "\n",
    "    def forward(self, X, A, y):\n",
    "        sigm_elems = y * (X @ self.w)\n",
    "        sigmas = F.logsigmoid(sigm_elems)\n",
    "        rez = torch.sum(sigmas) - 0.5 * self.w.T @ A @ self.w\n",
    "        return rez\n",
    "    def predict_proba(self, X):\n",
    "        sigm_elems = (X @ self.w)\n",
    "        sigmas = F.sigmoid(sigm_elems)\n",
    "        return sigmas\n",
    "\n",
    "def sample_predict(X_test, X_train, y_train, A):\n",
    "    # аппроксимируем правильный подсчет вероятностей\n",
    "    poster_coeff = np.exp(-0.5 * np.sum(X_train * X_train))\n",
    "    def compute_posterior(X_train, y_train, w):\n",
    "        sigm_elems = y * (X @ self.w)\n",
    "        sigmas = F.logsigmoid(sigm_elems)\n",
    "        rez = torch.sum(sigmas) - 0.5 * self.w.T @ A @ self.w\n",
    "        rez pos\n",
    "        return np.prod()\n",
    "    def one_sample():\n",
    "        w_sampler = multivariate_normal(mean = np.zeros(vec_size), cov = A)\n",
    "        tmp = w_sampler.rvs(1000)\n",
    "        probs = w_sampler.pdf(tmp)\n",
    "        sigmas = 1 / (1 + np.exp(-X))\n",
    "    w_s = np.random.multivariate_normal(mean = np.zeros((vec_size)), cov= A, size= (1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.26971333e-01  1.28395162e+00 -1.28424775e+00 -1.98607884e-01\n",
      "   1.89301360e+00  4.08555776e-01 -6.55319680e-01 -4.76188721e-01\n",
      "  -1.47161947e+00  8.68741127e-01]\n",
      " [ 6.29300769e-01 -5.62647880e-01 -3.91498665e-01  1.05022357e-01\n",
      "   7.60061631e-01  5.93317383e-02 -2.93036352e-01  6.67507234e-01\n",
      "   1.05934136e+00  5.01132476e-01]\n",
      " [ 1.69259052e+00  9.45203034e-01 -1.01075418e+00  1.58645900e+00\n",
      "  -7.58025351e-01  1.33516372e+00  3.85963320e-01 -3.70509957e-01\n",
      "  -5.12454628e-01 -1.66532177e-03]]\n",
      "0.00010211761384541846\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "A = np.eye(vec_size)\n",
    "norm = multivariate_normal(mean = np.zeros(vec_size), cov = A)\n",
    "tmp = norm.rvs(3)\n",
    "print(tmp)\n",
    "print(norm.pdf(np.zeros(vec_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "vec_size = 10\n",
    "elems = 100\n",
    "A = np.eye(vec_size)\n",
    "A = torch.Tensor(A)\n",
    "X = torch.rand((100, vec_size))\n",
    "y = torch.rand((elems)) > 0.3\n",
    "poster = posterior(A, vec_size)\n",
    "\n",
    "optim = torch.optim.AdamW([poster.w],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167.8400115966797\n",
      "27.5008487701416\n",
      "27.5008487701416\n",
      "27.50084686279297\n",
      "27.50084686279297\n",
      "27.50084686279297\n",
      "27.50084686279297\n",
      "27.5008487701416\n",
      "27.50084686279297\n",
      "27.50084686279297\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    tmp = -poster(X, A, y)\n",
    "    optim.zero_grad()\n",
    "    tmp.backward()\n",
    "    optim.step()\n",
    "    if i % 10000 == 0:\n",
    "        print(tmp.detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7804, 0.7265, 0.6909, 0.8099, 0.6750, 0.8989, 0.8006, 0.7572, 0.6551,\n",
       "        0.7853], requires_grad=True)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8900)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((poster.predict_proba(X) > 0.95) * 1.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
