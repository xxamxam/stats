{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2, norm, bernoulli, poisson\n",
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "from matplotlib. pyplot import imshow, imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.147286351300178 8.166666666666666\n"
     ]
    }
   ],
   "source": [
    "f_obs = np.array([9,20,14,8,11,10])  # observed (empirical) frequencies\n",
    "n = f_obs.sum()  # sample size\n",
    "N = len(f_obs)\n",
    "p_0 = np.ones(N) / N  # uniform categorical distribution\n",
    "f_exp = n * p_0  # expected frequencies\n",
    "t, p_value = chisquare(f_obs, f_exp)  # chi-squared test\n",
    "print(p_value, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat: 8.166666666666666; p_value: 0.14728635130017798\n"
     ]
    }
   ],
   "source": [
    "# сам посчитаю статистику\n",
    "statistics = np.sum((f_obs - f_exp)**2/f_exp)\n",
    "p_value = 1 - chi2.cdf(statistics, N - 1)\n",
    "print(f\"stat: {statistics}; p_value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p_value > alpha. Выборка не противоречит критерию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat: 5.125; p_value: 0.8232783432788753\n"
     ]
    }
   ],
   "source": [
    "f_obs = np.array([74, 92, 83, 79, 80, 73, 77, 75, 76, 91])\n",
    "n = f_obs.sum()\n",
    "N = len(f_obs)\n",
    "p_0 = np.ones(N)/N\n",
    "exp_freq = p_0 * n\n",
    "\n",
    "statistics = (((f_obs - exp_freq)**2) / exp_freq).sum()\n",
    "p_value = 1 - chi2.cdf(statistics, N-1)\n",
    "\n",
    "print(f\"stat: {statistics}; p_value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборка не противоречит гипотезе\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10\n",
    "В задаче нужно провести оценку параметра p. есть 4 события при испытаниях бернулли. (оо, ор, ро, рр). р - заболел, о - не заболел. Результаты (ор, ро) объединены в один. Распишем метод максимума правдоподобия и найдем параметр. Далее воспользуемся критерием Хи квадрат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=131.23466177606713, pvalue=3.182403754203728e-29)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 200\n",
    "f_obs = np.array([n - 181 - 9, 181, 9])\n",
    "p = 199./400\n",
    "exp_freq = n * np.array([(1-p)**2, 2 * p *(1-p), p**2])\n",
    "\n",
    "chisquare(f_obs, exp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pvalue $<< \\alpha$. Гипотезу отвергаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_valie: 3.5665697735942636e-05\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "N = 3\n",
    "obs_1 = np.array([25, 50, 25])\n",
    "obs_2 = np.array([52, 41, 7])\n",
    "n1 = sum(obs_1)\n",
    "n2 = sum(obs_2)\n",
    "n = float(n1 + n2) # так как будем делить\n",
    "apriori_p = (obs_1 + obs_2)/n\n",
    "obs = [obs_1, obs_2]\n",
    "n_s = [n1, n2]\n",
    "statistics = 0.\n",
    "for i in range(k):\n",
    "    for j in range(N):\n",
    "        statistics += (obs[i][j] - n_s[i]* apriori_p[j])**2 / (n_s[i] * apriori_p[j])\n",
    "    \n",
    "print(f\"p_valie: {1 - chi2.cdf(statistics, (k-1)*(N-1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "отвергаем гипотезу о независимости от номера партии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12\n",
    "\n",
    "проверяем гипотезы о равномерном распределении и о нормальном распределении. \n",
    "\n",
    "Сначала гипотеза о равномерном распределении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat = 16.4\n",
      "pvalue: 0.058984030544419586\n"
     ]
    }
   ],
   "source": [
    "# проверка гипотезы о равномерном распределении\n",
    "obs = np.array([5, 8, 6, 12, 14, 18, 11, 6, 13, 7])\n",
    "n = len(obs)\n",
    "N = obs.sum()\n",
    "apriori_p = np.ones((n), dtype=float)/n\n",
    "apriori_freq = apriori_p * N\n",
    "\n",
    "statistics = ((obs - apriori_freq)**2 / apriori_freq).sum()\n",
    "print(f'stat = {statistics}')\n",
    "print(f'pvalue: {1 - chi2.cdf(statistics, n - 1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "наблюдения не противоречат гипотезе\n",
    "\n",
    "далее рассмотрим нормальное распределение. Для него нужно будет воспользоваться методом максимума правдоподобия и найти параметры. \n",
    "\n",
    "Также оценим параметры в лоб. Это нам понадобится для построения квантизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 4.77; disp: 6.277100000000004\n"
     ]
    }
   ],
   "source": [
    "# проведем грубую оценку параметров\n",
    "numbers = np.array([i for i in range(10)])\n",
    "mean = np.sum(numbers * obs)/ N\n",
    "disp = np.sum(numbers**2 * obs)/N - mean**2\n",
    "print(f\"mean: {mean}; disp: {disp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как наблюдения дискретные, а распределение непрерывное, проведем квантизацию. А именно заведем корзины и поместим в них наблюдения. Мы посчитали среднее  = 4.77. По нему построим корзины: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-inf, 0.77, 1.77, 2.77, 3.77, 4.77, 5.77, 6.77, 7.77, 8.77,  inf])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas = np.linspace(0.77, 8.77, 9)\n",
    "deltas = np.concatenate([[-np.inf], deltas, [np.inf]])\n",
    "deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "и посчитаем сколько наблюдений попадает в каждую корзину. Эту величину обозначим $K_i$.\n",
    "\n",
    "Далее пользуемся методом максимума правдоподобия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Надеемся что полученные выражения являются сжатиями, и итерирование по ним сойдется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood mean: 5.059676805410929\n",
      " likelihood disp: 7.179825368644995\n"
     ]
    }
   ],
   "source": [
    "import scipy.integrate as integrate\n",
    "from scipy.stats import norm\n",
    "deltas = np.linspace(0.77, 8.77, 9)\n",
    "deltas = np.concatenate([[-np.inf], deltas, [np.inf]])\n",
    "mean\n",
    "disp\n",
    "\n",
    "def integr(func, i):\n",
    "    return integrate.quad(func,  deltas[i], deltas[i + 1])[0]\n",
    "while True:\n",
    "    new_mean = []\n",
    "    new_disp = []\n",
    "    f = lambda x: norm.pdf(x, loc = mean, scale = disp**0.5)\n",
    "    xf = lambda x: x * norm.pdf(x, loc = mean, scale = disp**0.5)\n",
    "    x_mu_f = lambda x: (x - mean) ** 2 * norm.pdf(x, loc = mean, scale = disp**0.5)\n",
    "    \n",
    "    for i in range(len(deltas) - 1):\n",
    "        new_mean.append( obs[i] *  integr(xf, i)/ integr(f, i))\n",
    "        new_disp.append(obs[i] *  integr(x_mu_f, i)/ integr(f, i))\n",
    "    new_mean = sum(new_mean)/N\n",
    "    new_disp = sum(new_disp)/N\n",
    "    if np.allclose([mean, disp], [new_mean, new_disp], atol = 1e-10):\n",
    "        disp = new_disp\n",
    "        mean = new_mean\n",
    "        break\n",
    "    disp = new_disp\n",
    "    mean = new_mean\n",
    "print(f\"likelihood mean: {mean}\\n likelihood disp: {disp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "и применим критерий хи-квадрат с этими параметрами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics: 9.80255496484806\n",
      "p_value: 0.2791584279175907\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: norm.pdf(x, loc = mean, scale = disp**0.5)\n",
    "apriori_p = np.array([integr(f, i) for i in range(10)])\n",
    "apriori_freq = N * apriori_p\n",
    "\n",
    "statistics = sum((obs - apriori_freq)**2 / apriori_freq)\n",
    "p_value = 1 - chi2.cdf(statistics, n -2)\n",
    "print(f\"statistics: {statistics}\")\n",
    "print(f\"p_value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p_value второй гипотезы больше. Полученная выборка больше похожа на нормальное распределение чем на равномерное (вроде такие выводы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попытка решить в лоб\n",
    "\n",
    "![Alt text](image-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другое решение. Тут я в начальную гипотезу добавил условие $n1 + n2 = k$, где $n1, n2$ - количество наблюдений на 1 час и за 2 часа соответственно. Таким образом мы рассматриваем выполнение гипотезы только на подмножестве распределений. Если гипотеза верна, то критерий должен выполняться и на этом подмножестве, поэтому можно так делать\n",
    "\n",
    "![Alt text](image-7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm approximation:\n",
      "p_value: 0.08 ;delta from mean: 16.67 ;acceptance interval :18.48\n",
      "poisson approximation\n",
      "p_value: 0.14 ;delta from mean: 16.67 ;acceptance interval :22.33\n",
      "true binomial\n",
      "p_value: 0.07 ;delta from mean: 16.67 ;acceptance interval :18.33\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm, poisson, binom\n",
    "n1 = 150\n",
    "n2 = 250\n",
    "p = 1./3\n",
    "n_obs = n1\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "def norm_crit(n_obs):\n",
    "    n = n1 + n2\n",
    "    mean = n * p\n",
    "    delta = abs(mean - n_obs)\n",
    "    quantile = -norm.ppf(alpha/2, loc = 0., scale = (n * p * (1 - p))**0.5)\n",
    "    p_value = norm.cdf(-delta, loc = 0., scale = (n * p * (1 - p))**0.5) + \\\n",
    "                    1 - norm.cdf(delta, loc = 0., scale = (n * p * (1 - p))**0.5)\n",
    "    return p_value, delta, quantile\n",
    "\n",
    "def poisson_crit(n_obs):\n",
    "    n = n1 + n2\n",
    "    mean = n * p\n",
    "    delta = abs(mean - n_obs)\n",
    "    quantile_delta = mean - poisson.ppf(alpha/2, mu = n * p)\n",
    "    p_value = poisson.cdf(mean - delta, mu = n * p) + \\\n",
    "                        1 -  poisson.cdf(mean + delta, mu = n * p)\n",
    "    return p_value, delta, quantile_delta\n",
    "\n",
    "def binom_crit(n_obs):\n",
    "    n = n1 + n2\n",
    "    mean = n * p\n",
    "    delta = abs(mean - n_obs)\n",
    "    quantile_delta = mean - binom.ppf(alpha/2, n = n, p = p)\n",
    "    p_value = binom.cdf(mean - delta,  n = n, p = p) + \\\n",
    "                        1 -  binom.cdf(mean + delta,  n = n, p = p)\n",
    "    return p_value, delta, quantile_delta\n",
    "\n",
    "print(\"norm approximation:\\np_value: {:.2f} ;delta from mean: {:.2f} ;acceptance interval :{:.2f}\".format(*norm_crit(n1)))\n",
    "print(\"poisson approximation:\\np_value: {:.2f} ;delta from mean: {:.2f} ;acceptance interval :{:.2f}\".format(*poisson_crit(n1)))\n",
    "print(\"true binomial:\\np_value: {:.2f} ;delta from mean: {:.2f} ;acceptance interval :{:.2f}\".format(*binom_crit(n1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "аппроксимация через пуассоновское распределение выдает бОльшее p_value, так как у пуассоновского распределения тяжелые хвосты.\n",
    "\n",
    "Аппроксимация через нормальное распределение показывает результаты более похожие на результат без аппроксимации.\n",
    "\n",
    "По обоим критериям наблюдения не противоречат гипотезе."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
